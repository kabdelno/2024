


import pandas as pd
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline
import seaborn as sns
import math
from math import exp
from statsmodels.stats import diagnostic
from scipy import stats
import statsmodels.api as sm
import statsmodels.formula.api as smf


data_folder = './data/'
df = pd.read_csv(data_folder + 'heart_failure_clinical_records_dataset.csv')





df.sample(10)


# 299 patients
len(df)





# Declares the model
model = smf.ols(formula='time ~ C(diabetes) + C(high_blood_pressure)', data=df)


# Fits the model (find the optimal coefficients, adding a random seed ensures consistency)
np.random.seed(2)
res = model.fit()


# Print thes summary output provided by the library.
print(res.summary())








print(df.loc[(df['diabetes'] == 0) & (df["high_blood_pressure"] == 0)]['time'].mean())
print(df.loc[(df['diabetes'] == 1) & (df["high_blood_pressure"] == 0)]['time'].mean())
print(df.loc[(df['diabetes'] == 0) & (df["high_blood_pressure"] == 1)]['time'].mean())
print(df.loc[(df['diabetes'] == 1) & (df["high_blood_pressure"] == 1)]['time'].mean())











# we use a*b to add terms: a, b, a:b, and intercept

mod = smf.ols(formula='time ~ C(high_blood_pressure) * C(DEATH_EVENT,  Treatment(reference=0)) + C(diabetes)',
              data=df)


res = mod.fit()

print(res.summary())

















# how we standardize the countinuous variables

df['age'] = (df['age'] - df['age'].mean())/df['age'].std()
df['creatinine_phosphokinase'] = (df['creatinine_phosphokinase'] - df['creatinine_phosphokinase'].mean())/df['creatinine_phosphokinase'].std()
df['ejection_fraction'] = (df['ejection_fraction'] - df['ejection_fraction'].mean())/df['ejection_fraction'].std()
df['platelets'] = (df['platelets'] - df['platelets'].mean())/df['platelets'].std()
df['serum_creatinine'] = (df['serum_creatinine'] - df['serum_creatinine'].mean())/df['serum_creatinine'].std()
df['serum_sodium'] = (df['serum_sodium'] - df['serum_sodium'].mean())/df['serum_sodium'].std()





# logit is logistic regression. The other parameters are the same as before

mod = smf.logit(formula='DEATH_EVENT ~  age + creatinine_phosphokinase + ejection_fraction + \
                        platelets + serum_creatinine + serum_sodium + \
                        C(diabetes) + C(high_blood_pressure) +\
                        C(sex) + C(anaemia) + C(smoking) + C(high_blood_pressure)', data=df)
res = mod.fit()
print(res.summary())





# feature names
variables = res.params.index

# quantifying uncertainty!

# coefficients
coefficients = res.params.values

# p-values
p_values = res.pvalues

# standard errors
standard_errors = res.bse.values

#confidence intervals
res.conf_int()





# sort them all by coefficients
l1, l2, l3, l4 = zip(*sorted(zip(coefficients[1:], variables[1:], standard_errors[1:], p_values[1:])))

# in this case, we index starting from the first element, not to plot the intercept

# we will use standard errors, instead of CIs
# two standard errors approximate the CIs (you can actually see in the summary table that
# +/2 SI is equivalent to the CIs)


# fancy plotting

plt.errorbar(l1, np.array(range(len(l1))), xerr= 2*np.array(l3), linewidth = 1,
             linestyle = 'none',marker = 'o',markersize= 3,
             markerfacecolor = 'black',markeredgecolor = 'black', capsize= 5)

plt.vlines(0,0, len(l1), linestyle = '--')

plt.yticks(range(len(l2)),l2);








np.seterr(divide = 'ignore') 
fig, axs = plt.subplots(1, 3, figsize=(14,3))
p = np.linspace(0, 0.99, 1000)
odds = p/(1-p)
axs[0].set_title("p vs. odds")
axs[0].plot(p, odds)
axs[0].set_xlabel("p")
axs[0].set_ylabel("odds")

axs[1].set_title("odds vs. log-odds")
axs[1].plot(odds, np.log(odds))
axs[1].set_xlabel("odds")
axs[1].set_ylabel("log odds")

axs[2].set_title("p vs. log-odds")
axs[2].plot(p, np.log(odds))
axs[2].set_xlabel("p")
axs[2].set_ylabel("log odds")





delta_logodds = 0.66
p = [0.1, 0.9]

def logoddsconversion(p, delta_logoods):
    for i in range(len(p)):
        p[i]=(exp(delta_logodds)*(p[i]/(1-p[i])))/(1+exp(delta_logodds)*(p[i]/(1-p[i])))
        print(p[i])

logoddsconversion(p, delta_logodds)






mod = smf.logit(formula='DEATH_EVENT ~ serum_creatinine', data=df)

np.random.seed(2)
res = mod.fit()
print(res.summary())







import scipy.stats as stats
stats.pearsonr(df["age"].values, df["serum_creatinine"])


##I would expect the coefficient to decrease as old people that do not have high amounts of serum-creatinine probably will decrease the correlation?

mod = smf.logit(formula='DEATH_EVENT ~ serum_creatinine * age', data=df)

np.random.seed(2)
res = mod.fit()
print(res.summary())

#guess I was right





# reload the data to undo the std transforms
data_folder = './data/'
df = pd.read_csv(data_folder + 'heart_failure_clinical_records_dataset.csv')


## 1
mod = smf.ols(formula = 'time ~ C(diabetes) + C(high_blood_pressure) + C(DEATH_EVENT, Treatment(reference=0))', data = df)
np.random.seed(2)
res1 = mod.fit()
print(res1.summary())


##2
df['log_time'] = np.log(df['time'])
mod = smf.ols(formula = 'log_time ~ C(diabetes) + C(high_blood_pressure) + C(DEATH_EVENT, Treatment(reference=0))', data = df) 
np.random.seed(2)
res = mod.fit()
print(res.summary())


print(f"The additive effect of high blood pressureon hospital stay is a decrease of {res1.params['C(high_blood_pressure)[T.1]']} days")

multiplicative_effect = (exp(res.params['C(high_blood_pressure)[T.1]'])-1)*100
print(f"The multiplicative effect of high blood pressureon hospital stay is a decrease of {multiplicative_effect}% in stay length")




